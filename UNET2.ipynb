{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3232986599409538318, name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 11493069543561676922\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 2225997533579591075\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11326753997\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 5657826677796447451\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "smooth = 1e-9\n",
    "\n",
    "# This is the competition metric implemented using Keras\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * (K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "# We'll construct a Keras Loss that incorporates the DICE score\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1. - (2. * intersection + 1.) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.)\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.5 * binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\"\"\"\n",
    "# Create simple model\n",
    "from keras.layers import Conv2D, Reshape\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, 5, activation='relu', padding='same', input_shape=(128, 128, 3)))\n",
    "model.add(Conv2D(128, 5, activation='relu', padding='same'))\n",
    "model.add(Conv2D(1, 5, activation='sigmoid', padding='same'))\n",
    "model.add(Reshape((128, 128)))\n",
    "          \n",
    "model.compile(Adam(lr=0.01), loss=bce_dice_loss, metrics=[dice_coef])     \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def unet(input_size = (128,128,3)):\n",
    "    inputs = Input(input_size)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same') (inputs)\n",
    "    c1 = Dropout(0.1) (c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu',  padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu',  padding='same') (p1)\n",
    "    c2 = Dropout(0.1) (c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu',  padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu',  padding='same') (p2)\n",
    "    c3 = Dropout(0.2) (c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu',  padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same') (p3)\n",
    "    c4 = Dropout(0.2) (c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu',  padding='same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same') (p4)\n",
    "    c5 = Dropout(0.3) (c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu',  padding='same') (c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu',  padding='same') (u6)\n",
    "    c6 = Dropout(0.2) (c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu',  padding='same') (c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu',  padding='same') (u7)\n",
    "    c7 = Dropout(0.2) (c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu',  padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu',  padding='same') (u8)\n",
    "    c8 = Dropout(0.1) (c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu',  padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu',  padding='same') (u9)\n",
    "    c9 = Dropout(0.1) (c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu',  padding='same') (c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "    \n",
    "    outputs = Reshape((128,128))(outputs)\n",
    "    \n",
    "    model = Model(input = inputs, output = outputs)\n",
    "    \n",
    "    \n",
    "\n",
    "    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    model.compile(Adam(lr=1e-3), loss=bce_dice_loss, metrics=[dice_coef])\n",
    "    #smaller learning rate seems to work better (1e-4 vs 1e-2)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train/53717_sat.jpg', 'train/12320_sat.jpg', 'train/53640_sat.jpg', 'train/12480_sat.jpg', 'train/27456_sat.jpg', 'train/40397_sat.jpg', 'train/34417_sat.jpg', 'train/24192_sat.jpg', 'train/42547_sat.jpg', 'train/18984_sat.jpg']\n",
      "['train/52857_msk.png', 'train/5009_msk.png', 'train/29412_msk.png', 'train/50596_msk.png', 'train/8066_msk.png', 'train/11225_msk.png', 'train/43068_msk.png', 'train/48526_msk.png', 'train/47933_msk.png', 'train/15692_msk.png']\n",
      "['val/76232_sat.jpg', 'val/71058_sat.jpg', 'val/73690_sat.jpg', 'val/79306_sat.jpg', 'val/74502_sat.jpg']\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "path_to_train = 'train'\n",
    "glob_train_imgs = os.path.join(path_to_train, '*_sat.jpg')\n",
    "glob_train_masks = os.path.join(path_to_train, '*_msk.png')\n",
    "\n",
    "train_img_paths = glob(glob_train_imgs)\n",
    "train_mask_paths = glob(glob_train_masks)\n",
    "print(train_img_paths[:10])\n",
    "print(train_mask_paths[:10])\n",
    "\n",
    "\n",
    "path_to_val = 'val'\n",
    "glob_val_imgs = os.path.join(path_to_val, '*_sat.jpg')\n",
    "val_img_paths = glob(glob_val_imgs)\n",
    "print(val_img_paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# This will be useful so we can construct the corresponding mask\n",
    "def get_img_id(img_path):\n",
    "    img_basename = os.path.basename(img_path)\n",
    "    img_id = os.path.splitext(img_basename)[0][:-len('_sat')]\n",
    "    return img_id\n",
    "\n",
    "# Write it like a normal function\n",
    "def image_gen(img_paths, img_size=(128, 128)):\n",
    "    # Iterate over all the image paths\n",
    "    for img_path in img_paths:\n",
    "        \n",
    "        # Construct the corresponding mask path\n",
    "        img_id = get_img_id(img_path)\n",
    "        mask_path = os.path.join(path_to_train, img_id + '_msk.png')\n",
    "        \n",
    "        # Load the image and mask, and normalize it to 0-1 range\n",
    "        img = imread(img_path) / 255.\n",
    "        mask = rgb2gray(imread(mask_path))\n",
    "        \n",
    "        # Resize the images\n",
    "        img = resize(img, img_size, preserve_range=True)\n",
    "        mask = resize(mask, img_size, mode='constant', preserve_range=True)\n",
    "        # Turn the mask back into a 0-1 mask\n",
    "        mask = (mask >= 0.5).astype(float)\n",
    "        \n",
    "        # Yield the image mask pair\n",
    "        yield img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Keras takes its input in batches \n",
    "# (i.e. a batch size of 32 would correspond to 32 images and 32 masks from the generator)\n",
    "# The generator should run forever\n",
    "def image_batch_generator(img_paths, batchsize=32):\n",
    "    while True:\n",
    "        ig = image_gen(img_paths)\n",
    "        batch_img, batch_mask = [], []\n",
    "        \n",
    "        for img, mask in ig:\n",
    "            # Add the image and mask to the batch\n",
    "            batch_img.append(img)\n",
    "            batch_mask.append(mask)\n",
    "            # If we've reached our batchsize, yield the batch and reset\n",
    "            if len(batch_img) == batchsize:\n",
    "                yield np.stack(batch_img, axis=0), np.stack(batch_mask, axis=0)\n",
    "                batch_img, batch_mask = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 128, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 16) 2320        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 16)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 64, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 32)   9248        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 64)   36928       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 128)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 128)  147584      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 128)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 256)    295168      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 8, 8, 256)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 256)    590080      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 128)  131200      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16, 16, 128)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 128)  147584      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 64)   32832       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 64)   73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 64)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 64)   36928       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 32)   8224        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 64)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 32)   18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64, 64, 32)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 32)   9248        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 128, 128, 16) 2064        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 128, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 16) 4624        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128, 128, 16) 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 16) 2320        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 1)  17          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 128, 128)     0           conv2d_19[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,941,105\n",
      "Trainable params: 1,941,105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:107: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"re...)`\n"
     ]
    }
   ],
   "source": [
    "model = unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 292s 1s/step - loss: 0.9885 - dice_coef: 0.0114 - val_loss: 0.9099 - val_dice_coef: 0.1616\n",
      "Epoch 2/35\n",
      "290/290 [==============================] - 283s 975ms/step - loss: 0.8151 - dice_coef: 0.2955 - val_loss: 0.7408 - val_dice_coef: 0.3663\n",
      "Epoch 3/35\n",
      "290/290 [==============================] - 286s 985ms/step - loss: 0.6692 - dice_coef: 0.4320 - val_loss: 0.6273 - val_dice_coef: 0.4695\n",
      "Epoch 4/35\n",
      "290/290 [==============================] - 287s 989ms/step - loss: 0.6020 - dice_coef: 0.4914 - val_loss: 0.5716 - val_dice_coef: 0.5182\n",
      "Epoch 5/35\n",
      "290/290 [==============================] - 290s 999ms/step - loss: 0.5677 - dice_coef: 0.5211 - val_loss: 0.5364 - val_dice_coef: 0.5508\n",
      "Epoch 6/35\n",
      "290/290 [==============================] - 289s 997ms/step - loss: 0.5419 - dice_coef: 0.5435 - val_loss: 0.5167 - val_dice_coef: 0.5677\n",
      "Epoch 7/35\n",
      "290/290 [==============================] - 289s 995ms/step - loss: 0.5244 - dice_coef: 0.5583 - val_loss: 0.5050 - val_dice_coef: 0.5781\n",
      "Epoch 8/35\n",
      "290/290 [==============================] - 287s 991ms/step - loss: 0.5136 - dice_coef: 0.5678 - val_loss: 0.5038 - val_dice_coef: 0.5796\n",
      "Epoch 9/35\n",
      "290/290 [==============================] - 286s 988ms/step - loss: 0.5016 - dice_coef: 0.5780 - val_loss: 0.4947 - val_dice_coef: 0.5871\n",
      "Epoch 10/35\n",
      "290/290 [==============================] - 285s 982ms/step - loss: 0.4947 - dice_coef: 0.5838 - val_loss: 0.4908 - val_dice_coef: 0.5904\n",
      "Epoch 11/35\n",
      "290/290 [==============================] - 288s 992ms/step - loss: 0.4845 - dice_coef: 0.5927 - val_loss: 0.4836 - val_dice_coef: 0.5965\n",
      "Epoch 12/35\n",
      "290/290 [==============================] - 284s 979ms/step - loss: 0.4792 - dice_coef: 0.5973 - val_loss: 0.4619 - val_dice_coef: 0.6142\n",
      "Epoch 13/35\n",
      "290/290 [==============================] - 286s 987ms/step - loss: 0.4685 - dice_coef: 0.6062 - val_loss: 0.4796 - val_dice_coef: 0.6000\n",
      "Epoch 14/35\n",
      "290/290 [==============================] - 284s 979ms/step - loss: 0.4598 - dice_coef: 0.6136 - val_loss: 0.4431 - val_dice_coef: 0.6309\n",
      "Epoch 15/35\n",
      "290/290 [==============================] - 285s 981ms/step - loss: 0.4532 - dice_coef: 0.6192 - val_loss: 0.4515 - val_dice_coef: 0.6230\n",
      "Epoch 16/35\n",
      "290/290 [==============================] - 284s 979ms/step - loss: 0.4490 - dice_coef: 0.6231 - val_loss: 0.4403 - val_dice_coef: 0.6337\n",
      "Epoch 17/35\n",
      "290/290 [==============================] - 284s 981ms/step - loss: 0.4416 - dice_coef: 0.6294 - val_loss: 0.4371 - val_dice_coef: 0.6370\n",
      "Epoch 18/35\n",
      "290/290 [==============================] - 285s 982ms/step - loss: 0.4353 - dice_coef: 0.6348 - val_loss: 0.4346 - val_dice_coef: 0.6389\n",
      "Epoch 19/35\n",
      "290/290 [==============================] - 288s 992ms/step - loss: 0.4334 - dice_coef: 0.6364 - val_loss: 0.4381 - val_dice_coef: 0.6365\n",
      "Epoch 20/35\n",
      "290/290 [==============================] - 284s 980ms/step - loss: 0.4277 - dice_coef: 0.6413 - val_loss: 0.4196 - val_dice_coef: 0.6519\n",
      "Epoch 21/35\n",
      "290/290 [==============================] - 286s 988ms/step - loss: 0.4241 - dice_coef: 0.6444 - val_loss: 0.4216 - val_dice_coef: 0.6495\n",
      "Epoch 22/35\n",
      "290/290 [==============================] - 284s 979ms/step - loss: 0.4173 - dice_coef: 0.6503 - val_loss: 0.4232 - val_dice_coef: 0.6510\n",
      "Epoch 23/35\n",
      "290/290 [==============================] - 285s 983ms/step - loss: 0.4160 - dice_coef: 0.6513 - val_loss: 0.4248 - val_dice_coef: 0.6498\n",
      "Epoch 24/35\n",
      "290/290 [==============================] - 281s 970ms/step - loss: 0.4127 - dice_coef: 0.6542 - val_loss: 0.4419 - val_dice_coef: 0.6362\n",
      "Epoch 25/35\n",
      "290/290 [==============================] - 288s 993ms/step - loss: 0.4175 - dice_coef: 0.6500 - val_loss: 0.4205 - val_dice_coef: 0.6529\n",
      "Epoch 26/35\n",
      "290/290 [==============================] - 285s 983ms/step - loss: 0.4047 - dice_coef: 0.6611 - val_loss: 0.4188 - val_dice_coef: 0.6546\n",
      "Epoch 27/35\n",
      "290/290 [==============================] - 284s 981ms/step - loss: 0.4008 - dice_coef: 0.6643 - val_loss: 0.4254 - val_dice_coef: 0.6497\n",
      "Epoch 28/35\n",
      "290/290 [==============================] - 285s 983ms/step - loss: 0.4059 - dice_coef: 0.6601 - val_loss: 0.4141 - val_dice_coef: 0.6568\n",
      "Epoch 29/35\n",
      "290/290 [==============================] - 287s 988ms/step - loss: 0.3965 - dice_coef: 0.6681 - val_loss: 0.4104 - val_dice_coef: 0.6590\n",
      "Epoch 30/35\n",
      "290/290 [==============================] - 284s 979ms/step - loss: 0.3939 - dice_coef: 0.6702 - val_loss: 0.4040 - val_dice_coef: 0.6640\n",
      "Epoch 31/35\n",
      "290/290 [==============================] - 286s 985ms/step - loss: 0.3930 - dice_coef: 0.6712 - val_loss: 0.4056 - val_dice_coef: 0.6610\n",
      "Epoch 32/35\n",
      "290/290 [==============================] - 286s 988ms/step - loss: 0.3910 - dice_coef: 0.6728 - val_loss: 0.4033 - val_dice_coef: 0.6641\n",
      "Epoch 33/35\n",
      "290/290 [==============================] - 286s 986ms/step - loss: 0.3895 - dice_coef: 0.6742 - val_loss: 0.4110 - val_dice_coef: 0.6584\n",
      "Epoch 34/35\n",
      "290/290 [==============================] - 282s 973ms/step - loss: 0.3841 - dice_coef: 0.6787 - val_loss: 0.3983 - val_dice_coef: 0.6680\n",
      "Epoch 35/35\n",
      "290/290 [==============================] - 284s 979ms/step - loss: 0.3832 - dice_coef: 0.6797 - val_loss: 0.3926 - val_dice_coef: 0.6739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import keras.callbacks\n",
    "BATCHSIZE = 32\n",
    "\n",
    "# Split the data into a train and validation set\n",
    "train_img_paths, val_img_paths = train_test_split(train_img_paths, test_size=0.15)\n",
    "\n",
    "# Create the train and validation generators\n",
    "traingen = image_batch_generator(train_img_paths, batchsize=BATCHSIZE)\n",
    "valgen = image_batch_generator(val_img_paths, batchsize=BATCHSIZE)\n",
    "\n",
    "def calc_steps(data_len, batchsize):\n",
    "    return (data_len + batchsize - 1) // batchsize\n",
    "\n",
    "# Calculate the steps per epoch\n",
    "train_steps = calc_steps(len(train_img_paths), BATCHSIZE)\n",
    "val_steps = calc_steps(len(val_img_paths), BATCHSIZE)\n",
    "\n",
    "filepath=\"unet.hdf5\"\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=False, save_weights_only=True, mode='auto', period=1)\n",
    "callbacks_list = [checkpoint]\n",
    "# Train the model\n",
    "history = model.fit_generator(\n",
    "    traingen, \n",
    "    steps_per_epoch=train_steps, \n",
    "    epochs= 35, # Change this to a larger number to train for longer\n",
    "    validation_data=valgen, \n",
    "    validation_steps=val_steps, \n",
    "    verbose=1,\n",
    "    max_queue_size=5, # Change this number based on memory restrictions\n",
    "    callbacks = callbacks_list \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:107: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"re...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model = unet() #create new unet model\n",
    "#model.load_weights('unet.hdf5') #load model with pre-saved weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create submission DataFrame\n",
    "def create_submission(csv_name, predictions_gen):\n",
    "    \"\"\"\n",
    "    csv_name -> string for csv (\"XXXXXXX.csv\")\n",
    "    predictions -> generator that yields a pair of id, prediction\n",
    "    \"\"\"\n",
    "    sub = pd.DataFrame()\n",
    "    ids = []\n",
    "    encodings = []\n",
    "    num_images = len(val_img_paths)\n",
    "    for i in range(num_images):\n",
    "        if (i+1) % (num_images//10) == 0:\n",
    "            print(i, num_images)\n",
    "        img_id, pred = next(predictions_gen)\n",
    "        ids.append(img_id)\n",
    "        #print (np.count_nonzero(pred == 1))\n",
    "        encodings.append(rle_encoding(pred))\n",
    "        \n",
    "    sub['EncodedPixels'] = encodings\n",
    "    sub['ImageId'] = ids\n",
    "    sub.to_csv(csv_name, index=False)\n",
    "\n",
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    \"\"\"\n",
    "    x = numpyarray of size (height, width) representing the mask of an image\n",
    "    if x[i,j] == 0:\n",
    "        image[i,j] is not a road pixel\n",
    "    if x[i,j] != 0:\n",
    "        image[i,j] is a road pixel\n",
    "    \"\"\"\n",
    "    dots = np.where(x.T.flatten() != 0)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): \n",
    "            run_lengths.extend((b+1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_pixel_by_pixel_predictions_generator(val_paths):\n",
    "    for img_path in val_paths:        \n",
    "        img = imread(img_path) / 255.\n",
    "        img = resize(img, (128, 128), preserve_range=True)    \n",
    "        y = model.predict(img.reshape(1,128,128,3))  \n",
    "        y = (y >= 0.5).astype(float) #IMPORTANT- need this or you won't have 0 or 1 (because outputs are probabilities!!)\n",
    "        yield get_img_id(img_path), y.reshape(128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215 2169\n",
      "431 2169\n",
      "647 2169\n",
      "863 2169\n",
      "1079 2169\n",
      "1295 2169\n",
      "1511 2169\n",
      "1727 2169\n",
      "1943 2169\n",
      "2159 2169\n",
      "49.54658555984497\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "path_to_train = 'train'\n",
    "glob_train_imgs = os.path.join(path_to_train, '*_sat.jpg')\n",
    "glob_train_masks = os.path.join(path_to_train, '*_msk.png')\n",
    "train_img_paths = glob(glob_train_imgs)\n",
    "path_to_val = 'val'\n",
    "glob_val_imgs = os.path.join(path_to_val, '*_sat.jpg')\n",
    "val_img_paths = glob(glob_val_imgs)\n",
    "\n",
    "\n",
    "#first_img, first_mask = next(ig)\n",
    "\n",
    "img_size = (128,128)\n",
    "for i in range(20): \n",
    "    \n",
    "    img_id = get_img_id(train_img_paths[i])\n",
    "    mask_path = os.path.join(path_to_train, img_id + '_msk.png')\n",
    "           \n",
    "    img = imread(train_img_paths[i]) / 255.\n",
    "    mask = rgb2gray(imread(mask_path))\n",
    "    img = resize(img, img_size, preserve_range=True)\n",
    "    mask = resize(mask, img_size, mode='constant', preserve_range=True)    \n",
    "    mask = (mask >= 0.5).astype(float)\n",
    "    \n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    y = model.predict(img.reshape(1,128,128,3)) \n",
    "    y = (y.reshape(128,128) >= 0.5).astype(float)\n",
    "    \n",
    "    plt.imshow(y, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    img = imread(val_img_paths[i]) / 255.\n",
    "    img = resize(img, (128, 128), preserve_range=True)  \n",
    "    print (get_img_id(val_img_paths[i]))\n",
    "    y = model.predict(img.reshape(1,128,128,3)) \n",
    "    y = (y >= 0.5).astype(float)\n",
    "    #print (np.count_nonzero(y == 1))\n",
    "    #print (y)\n",
    "    plt.imshow(y.reshape(128,128), cmap='gray')\n",
    "    plt.show()\n",
    "\"\"\"   \n",
    "\n",
    "\"\"\"\n",
    "tic = time.time()\n",
    "create_submission(\"unet.csv\", generate_pixel_by_pixel_predictions_generator(val_img_paths))\n",
    "toc = time.time()\n",
    "print(toc - tic)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
